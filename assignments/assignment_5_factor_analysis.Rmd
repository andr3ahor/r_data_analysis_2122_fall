---
title: "Assignment 6: Factor Analysis"
author: "Marton Kovacs / Zoltan Kekecs"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction

In this lab assignment you will need to explore the factor structure of the Animal Rights Scale, a scale containing 28 items to measure attitudes towards animal experimentation and animal rights. Imagine that you are a researcher who is interested in the underlying factors that govern attitudes towards animal rights and the use of animals for different purposes. You have gathered data using the Animal Rights Scale (ARS) from 154 individuals in an online survey. Your goal is to explore the underlying factors.

# Dataset

You can load the dataset from the 'data/' folder.

The dataset includes the responses of 154 individuals on the following variables:

__ar1-ar28__ contain the data from the 28 items of the ARS. Participants had to rate their agreement with each statement separately on a 1-5 Likert scale with the following anchors: 1 - strongly disagree, 2 – disagree, 3 - no opinion, 4 – agree, 5 - strongly agree.

The questions in the ARS were the following:

  * __ar 1.__ Humans have no right to displace wild animals by converting wilderness areas into farmlands, cities, and other things designed for people.
  * __ar 2.__ Animal research cannot be justified and should be stopped.
  * __ar 3.__ It is morally wrong to drink milk and eat eggs.
  * __ar 4.__ A human has no right to use a horse as a means of transportation (riding) or entertainment (racing).
  * __ar 5.__ It is wrong to wear leather jackets and pants.
  * __ar 6.__ Most medical research done on animals is unnecessary and invalid.
  * __ar 7.__ I have seriously considered becoming a vegetarian in an effort to save animal lives.
  * __ar 8.__ Pet owners are responsible for preventing their pets from killing other animals, such as cats killing mice or snakes eating live mice.
  * __ar 9.__ We need more regulations governing the use of animals in research.
  * __ar 10.__ It is morally wrong to eat beef and other "red" meat.
  * __ar 11.__ Insect pests (mosquitoes, cockroaches, flies, etc.) should be safely removed from the house rather than killed.
  * __ar 12.__ Animals should be granted the same rights as humans.
  * __ar 13.__ It is wrong to wear leather belts and shoes.
  * __ar 14.__ I would rather see humans die or suffer from disease than to see animals used in research.
  * __ar 15.__ Having extended basic rights to minorities and women, it is now time to extend them also to animals.
  * __ar 16.__ God put animals on Earth for man to use.
  * __ar 17.__ There are plenty of viable alternatives to the use of animals in biomedical and behavioral research.
  * __ar 18.__ Research on animals has little or no bearing on problems confronting people.
  * __ar 19.__ New surgical procedures and experimental drugs should be tested on animals before they are used on people.
  * __ar 20.__ I am very concerned about pain and suffering in animals.
  * __ar 21.__ Since many important questions cannot be answered by doing experiments on people, we are left with no alternatives but to do animal research.
  * __ar 22.__ It is a violation of an animal's rights to be held captive as a pet by a human.
  * __ar 23.__ It is wrong to wear animal fur (such as mink coats).
  * __ar 24.__ It is appropriate for humans to kill animals that destroy human property, for example, rats, mice, and pigeons.
  * __ar 25.__ Most cosmetics research done on animals is unnecessary and invalid.
  * __ar 26.__ It is morally wrong to eat chicken and fish.
  * __ar 27.__ Most psychological research done on animals is unnecessary and invalid.
  * __ar 28.__ Hunters play an important role in regulating the size of deer populations.

You can get more information about the ARS here: http://core.ecu.edu/psyc/wuenschk/Animals/Anim-Rights-Q.htm

And also here: 

Wuensch, K. L., Jenkins, K. W., & Poteat, G. M. (2002). Misanthropy, idealism, and attitudes towards animals. _Anthrozoös, 15_, 139-149

Sharp, H. W., Wuensch, K. L., Eppler, M. A., & Harju, B. L. (2006, April). Narcissism, empathy, and attitudes towards animals. In _Spring Conference of the North Carolina Psychological Association and North Carolina Psychological Foundation, Charlotte, NC._

A few other questions were also included in the questionnaire:

__sex:__ The self reported sex of the participant. This is a categorical variable coded as 1 – female, 2 – male.

__party:__ Self reported party affiliation of the person (in the USA). This is a categorical variable coded as 1 - democrat, 2 - republican, 3 - other, 4 – none.

__liberal:__ This variable contains data from a question: please rate how conservative or liberal are you. On a scale of 1-5 where 1 means very conservative and 5 means very liberal. 

# Task

Your task is to do an exploratory factor analysis using the items in the ARS to identify the latent factors underlying the responses. First of all, start by exploring the descriptive statistics and correlations in the dataset to get more familiar with it and to identify any unusual cases or coding errors. Make sure to check the assumptions of factorability and multivariate normality and address them as necessary. You have a free hand in choosing the extraction and rotation methods. You can also exclude items if you see this necessary, but __do not exclude more than 8 items__ in this assignment. (If you still find the average communality below expectations, just report this as a limitation in your report, but continue the task). Keep notes of the steps and different setting/methods you tried during the exploratory factor analysis. 

_(The factor structure of this scale has been previously analyzed by others. If you want, you can use these previous research reports to guide your exploration, or you can ignore them. In any case, do not base your decisions solely on these research reports. Do your own work and base your decisions on your own findings on this dataset.)_

When you have arrived at the factor structure you consider final, give names to the factors you derived from the data. Save the factor scores and build a linear regression model to predict how conservative or liberal participants are (using the “liberal” variable as a dependent variable) with the factors you identified as the predictors.

__To simplify the task you can regard all likert scale variables (ar1-28 and liberal) as if they were continuous variables!__ So you do not have to use polychoric correlation for factor analysis and you do not have to perform ordinal regression.

# What to report

Report if you have found any unusual things (outliers or coding errors) in the dataset and how you dealt with them. Report the results of the assumption checks for factorability and multivariate normality. If any of the assumptions were found to be violated, report what was done to handle that. 

Report the number of factors you chose to keep in your final factor structure and give a rationale why. Include the parallel analysis scree plot in your report. Report the post-extraction eignevalues, variance explained, and cumulative variance explained by the final factors in a table format. Report the average post-extraction communality of the items. 

Report which rotation you chose to use (if any) and why. Report the final factor structure including the factor names. Also, report the post-extraction commonalities of each item and the loadings of the items on the final factors in a table format. (These can be reported in the same table). This table should contain the loadings that you used to interpret the factors in your analysis (e.g. the loadings listed in the rotated factor matrix or the pattern matrix). The table should be structured in a way to help the reader easily see which items load high on which factors.

Report if you have excluded any items, and give a rationale for each. 

Report which factor (if any) was the most influential predictor of how liberal a person is in the linear regression model and explain what do you base this assessment on.

# What to discuss

Talk about the limitations of your study and findings. 

# Solution

## Read the data

Read the Animal Rights Scale (ARQ) dataset from the 'data/' folder. Pay attention to the extension.

```{r}
asr_raw <- readr::read_csv('https://raw.githubusercontent.com/andr3ahor/r_data_analysis_2122_fall/master/data/assignment_5_dataset.csv')
library(psych)
library(Hmisc)
```

## EDA

```{r}
str(asr_raw)
summary(asr_raw)

#NA azonosítása
library(dplyr)
library(visdat)
which(is.na(data_frame), arr.ind=TRUE)
sum(is.na(asr_raw)) #11 hiányzó adat
colSums(is.na(asr_raw)) #oszlponokénti hiányzók

#Vizuálisan --> feltehetően randomok a hiányzó adatok, kevés adat hiányzik (0.2%)
visdat::vis_miss(asr_raw)

#NA adatok pótlása mediánnal, nem akartam törölni, mert az adatvesztéssel jár. Ez pedig egy sokak által ajánlott lehetőség. Megtehettem volna, hogy a kalkulációkból kihagyom őket (na.rm = TRUE), de minden faktor esetében ugyanannyi adattal szerettem volna dolgozni.
tidy_asr <- asr_raw %>% 
    mutate_if(is.numeric, function(x) ifelse(is.na(x), median(x, na.rm = T), x))


#látható, hogy több outlier is van. Mivel EFA-t szeretnék csinálni, ezért ezeket az adatokat most benne hagyom - de az eredményt ezek tükrében fogom értelmezni.

#Nem derül ki az adatok leírásából, hogy a fordított itemek már fordítva vannak-e benne az adathalmazban.

#Eloszlások
par(mar=c(1,1,1,1)) #mert ezt íRta ki előtte: Error in plot.new() : figure margins too large
hist(tidy_asr[c(1:28)])

data <- tidy_asr[1:154, 1:28]
df <- data.frame(tidy_asr)

#Otlier adatok azonosítása 
boxplot(tidy_asr[c(1:28)])
outliers <- psych::outlier(data)

#adat jellemzői összesítve
psych::describe(data)
```

## Data manipulation

Recode the sex and party variables as factor type variables with the following levels:
  * sex: 1 - male, 2 - female
  * party: 1 - democrat, 2 - republican, 3 - other, 4 - none

```{r}
recoded <- tidy_asr %>% mutate(sex = recode(sex, 
                                 "1" = "male",
                                 "2" = "female"))
recoded <- tidy_asr %>% mutate(party = recode(party, 
                                 "1" = "democrat",
                                 "2" = "republican",
                                 "3" = "other",
                                 "4" = "none"))

```

# Creating a correlation matrix

__Note:__ Remember to only include the variables of the questionnaire that will be part of the factor analysis.

```{r}
library(ggcorrplot)
library(ggplot2)

```

Create the correlation matrix.

```{r}
asr.cor <- cor(data) 
asr.cor <- round(asr.cor, 2)
asr.rcorr<-rcorr(as.matrix(data))
valtozo <- round(asr.rcorr$P, 2) #látható, hogy helyenként nincs szignifikáns korreláció, de a legtöbb érték esetében igen
```

## Visualizing the correlation matrix

Create a visualization of the results of the correlation matrix.

```{r}
library(psycho)
library(tidyverse)
library(corrplot)

p1 <- ggcorrplot(asr.cor, 
           hc.order = FALSE, 
           type = "upper",
           lab = FALSE)

corrplot(asr.cor, method = "color",  
         type = "lower", order = "original", 
         addCoef.col = "black", 
         tl.col = "darkblue", tl.srt = 45,
         sig.level = 0.01,  
         diag = FALSE)
#elmentve szebbre a assignments/assignment_5 mappába
```

## Test for factorability

Calculate the KMO score.

```{r}
# library(psych) kell hozzá

asr_kmo <- KMO(data)
print(asr_kmo)
#overall MSA = 0.88 felett, legalacsonyabb: ar28= 0.77 --> ez így elég jó

#megnéztem azért, hogy ar28 nélkül lenne-e változás, de nincs
asr_kmo2 <- KMO(data[c(1:27)])
print(asr_kmo)

#benne hagyom mindegyik itemet
```

## Test for multivariate normality

```{r}
#install.packages("mvnormtest")
library(mvnormtest)
#install.packages("MVN")
library(MVN)

#Mardia’s MVN tes
result <- mvn(data, mvnTest = "mardia")
result$multivariateNormality

# Henze-Zirkler’s MVN test
result.hz <- mvn(data, mvnTest = "hz")
result.hz$multivariateNormality

# Shapiro-Wilk
result.sh <- mshapiro.test(t(data))

#mindkét teszt az MVN hiányát jelzi, a normalitás sérül. Nem csinálhatunk maximum likelyhood elemzést.

#Bartlett
bartlett <- cortest.bartlett(data)
#a p érték megfelelőnek mutatkozik, elvégezhető a faktoranalízis, mert van valamiféle korreláció.
```

Test for skewness and kurtosis.

```{r}
#install.packages("QuantPsyc")
library(QuantPsyc)
normality <- mult.norm(data)$mult.test
print(normality) #sérül a a ferdeség és a csúcsosság is. Mivel azonban a KMO nagyon bíztató, és a Bartlett is, elvégeztem a faktor analízist.


```

## Create scree plot

Create a scree plot to help the decision on how many factors to include.

```{r}
scree(data)
#ábra mentve az assingment_5 mappába
#az ábra alapján 1, 2 vagy esetleg 6 faktort ajánl az alapján, hogy hol van az eigenvalue vonal és hol törik meg a vonal.

#Emiatt csináltam egy paralell scree plotot is, ez is mentve
fa.parallel(data)

#A szimulált adatok alapján 2 vagy 3 faktor ajánlott. Én ezek alapján a 3 faktoros felépítést fogom elkészíteni.
```

## Run the factor analysis

Run the factor analysis with the chosen number of factors.

```{r}
#install.packages("GPArotation")
library(GPArotation)

# 3 faktorral, oblimin forgatással, mert korrelációt várok a faktorok között
efa3 <- fa(data,
          nfactors = 3,
          fm="pa",
          rotate = "oblimin")



fa.diagram(efa3) #látható, hogy a 2. faktor igen instabil és kevés item van rajta. Ezért megcsináltam a 2 faktoros változatot is.

efa2 <- fa(data,
          nfactors = 2,
          fm="pa",
          rotate = "oblimin")

fa.diagram(efa2)

#Ez lesz a végső struktúra, megfelelőek a faktortöltések is.Egyedül a 8. tétel nem illeszkedik semleyik faktorra, ezt én kivenném a végső kérdőívből.

#mentve assignment_5 mappába az ábrák

```

Sort the communality scores in decreasing order.

```{r}

communa2 <- efa2$communality
commun2 <- sort(communa2, decreasing = TRUE)
commun2 <- round(commun2, 3)

#cumulative variance
round(efa2$Vaccounted,2)

#eigen values
eigen <- efa3$e.values
eigen <- round(eigen,3)

```

Calculate the mean communality scores.

```{r}
mean_c2 <- mean(commun2)

```

Show the factor loadings for the chosen factor structure.

```{r}
load <- efa2$loadings
fac1 = efa2$loadings[,1]
fac2 = efa2$loadings[,2]


factors <- data.frame(F1_rights = fac1 , 
           F2_research = fac2)
factors <- round(factors,3) 

#Láthatóvá tettem, hogy melyik item melyik faktorban, mekkora töltéssel van jelen.
factors[1,][which.min(factors[1,])] <- ""
factors[2,][which.min(factors[2,])] <- ""
factors[3,][which.min(factors[3,])] <- ""
factors[4,][which.min(factors[4,])] <- ""
factors[5,][which.min(factors[5,])] <- ""
factors[6,][which.min(factors[6,])] <- ""
factors[7,][which.min(factors[7,])] <- ""
factors[8,][which.min(factors[8,])] <- ""
factors[9,][which.min(factors[9,])] <- ""
factors[10,][which.min(factors[10,])] <- ""
factors[11,][which.min(factors[11,])] <- ""
factors[12,][which.min(factors[12,])] <- ""
factors[13,][which.min(factors[13,])] <- ""
factors[14,][which.min(factors[14,])] <- ""
factors[15,][which.min(factors[15,])] <- ""
factors[16,][which.max(factors[16,])] <- ""
factors[17,][which.min(factors[17,])] <- ""
factors[18,][which.min(factors[18,])] <- ""
factors[19,][which.max(factors[19,])] <- ""
factors[20,][which.min(factors[20,])] <- ""
factors[21,][which.max(factors[21,])] <- ""
factors[22,][which.min(factors[22,])] <- ""
factors[23,][which.min(factors[23,])] <- ""
factors[24,][which.max(factors[24,])] <- ""
factors[25,][which.min(factors[25,])] <- ""
factors[26,][which.min(factors[26,])] <- ""
factors[27,][which.max(factors[27,])] <- ""
factors[28,][which.max(factors[28,])] <- ""


```

Visualize the factor structure.

```{r}
#install.packages("kableExtra")
library(kableExtra)

fa.diagram(efa2) #final names?

#Faktorok nevei
colnames(efa2$loadings) <- c("F1:Attitude to animal's rights", "F2:Attitude to animal research")
final <- fa.diagram(efa2) #mentve final_efa2 képben

#Final táblázat: Factor loadings és eigen_v, communality
table1 <- cbind(Communality = commun2, Eigen_v = eigen, factors)
table1 <- arrange(table1, desc(F1_rights),desc(F2_research))

table1 %>%
    kbl() %>%
    kable_styling()

#Táblázat csak a faktortöltésekről
table2 <- table1[c("F1_rights","F2_research")]

table2 %>%
    kbl() %>%
    kable_styling()

#cumulative variance
Cum_var <- round(efa2$Vaccounted,2)



```

## Run linear regression

Calculate the factor scores.

```{r}
scores <- round(efa2$scores, 1)
```

Bind factor scores to the original dataset.

```{r}
regr_data <- cbind(scores, tidy_asr)
regr_data <- regr_data %>% 
       rename(
               F1_rights = PA1,
               F2_research = PA2)
```

Run the logistic regression.

```{r}
library(readxl)
lmliberal = lm(liberal~F1_rights+F2_research, data = regr_data)
summary(lmliberal)
#Az F érték mutatja, hogy egy szignifikáns elemzést hajtottunk végre, melyben az F1_rights faktor prediktálja szignifikánsan, míg az F2 17% eséllyel nem prediktál értelmezhető mértékben.
#az R2 sajnos nem túl jó, nem annyira jól illeszkedik a predikció.

plot(lmliberal, pch = 16, col = "blue") #mentve 2 residual ábra, a valós és prediktált között elég angy eltérések vannak.
plot(lmliberal$residuals, pch = 16, col = "red") #Láthatóan egész randomok a reziduálisok, tehát nincs a háttérben rejtett pattern.Mentve random_residual néven

#Discussion

#Ha újrakezdeném, lehet, hogy kivenném az outlier adatokat és összevetném az eddigi számításokkal. Hogy lássam, mennyit változtat rajta.  Lehet, hogy kivenném az 5. vagy 13. itemet, mert ezek nagyon erősen korrelálnak és tartalmilag is kicsit átfednek. Persze jobb lenne az egészet egy nagyobb mintán elvégezni, ahol akár a hiányzó adatok törlésére is van lehetőség. Itt most túl kevés adat volt ehhez.
```

